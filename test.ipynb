{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3603, -1.5605,  0.9497, -0.2348, -0.0369],\n",
       "        [ 0.3642,  0.7602, -1.9142,  0.1980,  0.4829],\n",
       "        [-0.8092, -0.2852,  0.5729, -0.3688,  0.8005],\n",
       "        [-1.6383,  0.4493, -0.4225,  0.7692,  2.2470],\n",
       "        [-0.7717,  0.1226,  0.0510, -0.6089,  0.4468]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(5, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3603, -1.5605,  0.9497, -0.2348, -0.0369],\n",
       "          [ 0.3642,  0.7602, -1.9142,  0.1980,  0.4829],\n",
       "          [-0.8092, -0.2852,  0.5729, -0.3688,  0.8005],\n",
       "          [-1.6383,  0.4493, -0.4225,  0.7692,  2.2470],\n",
       "          [-0.7717,  0.1226,  0.0510, -0.6089,  0.4468]]]),\n",
       " torch.Size([1, 5, 5]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.unsqueeze(0)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.6788e-01, 1.3534e-01, 4.9787e-02, 1.8316e-02, 6.7379e-03, 2.4788e-03,\n",
       "         9.1188e-04, 3.3546e-04]),\n",
       " tensor([0.6065, 0.3679, 0.2231, 0.1353, 0.0821, 0.0498, 0.0302, 0.0183]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = torch.tensor([1,2,3,4,5,6,7,8])\n",
    "torch.exp(-distance / 1), torch.exp(-distance / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import os.path as osp\n",
    "from yaml import SafeLoader\n",
    "from Data.get_data import get_data\n",
    "from run import run\n",
    "from run_batch import run_batch\n",
    "from Data.data_utils import load_fixed_splits\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings('ignore')\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', type=str, default='Cora')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4)\n",
    "    parser.add_argument('--gcn_wd', type=float, default=5e-4)\n",
    "    parser.add_argument('--gpu_id', type=int, default=6)\n",
    "    parser.add_argument('--config', type=str, default='config.yaml')\n",
    "    parser.add_argument('--gcn_use_bn', action='store_true', help='gcn use batch norm')\n",
    "    parser.add_argument('--show_details', type=bool, default=True)\n",
    "    parser.add_argument('--gcn_type', type=int, default=1)\n",
    "    parser.add_argument('--gcn_layers', type=int, default=2)\n",
    "    parser.add_argument('--batch_size', type=int, default=100000)\n",
    "    parser.add_argument('--rand_split', action='store_true', help='random split dataset')\n",
    "    parser.add_argument('--rand_split_class', action='store_true', help='random split dataset by class')\n",
    "    parser.add_argument('--protocol', type=str, default='semi')\n",
    "    parser.add_argument('--label_num_per_class', type=int, default=20)\n",
    "    parser.add_argument('--train_prop', type=float, default=.6)\n",
    "    parser.add_argument('--valid_prop', type=float, default=.2)\n",
    "    parser.add_argument('--alpha', type=float, default=.8)\n",
    "    parser.add_argument('--tau', type=float, default=.3)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    assert args.gpu_id in range(0, 8)\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "    config = yaml.load(open(args.config), Loader=SafeLoader)[args.dataset]\n",
    "    fix_seed(config['seed'])\n",
    "\n",
    "    # path = osp.join(osp.expanduser('~'), 'datasets/')\n",
    "    path = '/Users/jihaoran/PycharmProjects/CoBFormer/Data'\n",
    "\n",
    "    results = dict()\n",
    "    alpha = args.alpha\n",
    "    tau = args.tau\n",
    "\n",
    "    # postfix = f'{n_patch}'\n",
    "    postfix = \"test\"\n",
    "    runs = 5\n",
    "\n",
    "    data = get_data(path, args.dataset)\n",
    "    \n",
    "    # calculate calibration mask\n",
    "    # step 1: calculate shortest path distance matrix\n",
    "    # step 2: calculate calibration mask: exp(-distance/tau)\n",
    "    data.graph['calibration_mask'] = None\n",
    "    \n",
    "    # get the splits for all runs\n",
    "    if args.rand_split:\n",
    "        split_idx_lst = [data.get_idx_split(train_prop=args.train_prop, valid_prop=args.valid_prop)\n",
    "                         for _ in range(runs)]\n",
    "    elif args.rand_split_class:\n",
    "        split_idx_lst = [data.get_idx_split(split_type='class', label_num_per_class=args.label_num_per_class)\n",
    "                         for _ in range(runs)]\n",
    "    else:\n",
    "        split_idx_lst = load_fixed_splits(path, data, name=args.dataset, protocol=args.protocol)\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    results = [[], []]\n",
    "    for r in range(runs):\n",
    "        if args.dataset in ['Cora', 'CiteSeer', 'PubMed', 'ogbn-arxiv', 'ogbn-products'] and args.protocol == 'semi':\n",
    "            split_idx = split_idx_lst[0]\n",
    "        else:\n",
    "            split_idx = split_idx_lst[r]\n",
    "\n",
    "        if args.dataset in ['ogbn-products']:\n",
    "            res_gnn, res_trans = run_batch(args, config, device, data, batch_size, split_idx, alpha, tau,\n",
    "                                           postfix)\n",
    "        else:\n",
    "            res_gnn, res_trans = run(args, config, device, data, split_idx, alpha, tau, postfix)\n",
    "        results[0].append(res_gnn)\n",
    "        results[1].append(res_trans)\n",
    "\n",
    "    print(f\"==== Final GNN====\")\n",
    "    result = torch.tensor(results[0]) * 100.\n",
    "    print(result)\n",
    "    print(f\"max: {torch.max(result, dim=0)[0]}\")\n",
    "    print(f\"min: {torch.min(result, dim=0)[0]}\")\n",
    "    print(f\"mean: {torch.mean(result, dim=0)}\")\n",
    "    print(f\"std: {torch.std(result, dim=0)}\")\n",
    "\n",
    "    print(f'GNN Micro: {torch.mean(result, dim=0)[1]:.2f} ± {torch.std(result, dim=0)[1]:.2f}')\n",
    "    print(f'GNN Macro: {torch.mean(result, dim=0)[3]:.2f} ± {torch.std(result, dim=0)[3]:.2f}')\n",
    "\n",
    "    print(f\"==== Final Trans====\")\n",
    "    result = torch.tensor(results[1]) * 100.\n",
    "    print(result)\n",
    "    print(f\"max: {torch.max(result, dim=0)[0]}\")\n",
    "    print(f\"min: {torch.min(result, dim=0)[0]}\")\n",
    "    print(f\"mean: {torch.mean(result, dim=0)}\")\n",
    "    print(f\"std: {torch.std(result, dim=0)}\")\n",
    "\n",
    "    print(f'Trans Micro: {torch.mean(result, dim=0)[1]:.2f} ± {torch.std(result, dim=0)[1]:.2f}')\n",
    "    print(f'Trans Macro: {torch.mean(result, dim=0)[3]:.2f} ± {torch.std(result, dim=0)[3]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵1:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "矩阵2:\n",
      "[[5 6]\n",
      " [7 8]]\n",
      "对应位置元素相乘的结果:\n",
      "[[ 5 12]\n",
      " [21 32]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建两个形状相同的矩阵\n",
    "matrix1 = np.array([[1, 2], [3, 4]])\n",
    "matrix2 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# 对应位置的元素相乘\n",
    "result = matrix1 * matrix2\n",
    "\n",
    "print(\"矩阵1:\")\n",
    "print(matrix1)\n",
    "print(\"矩阵2:\")\n",
    "print(matrix2)\n",
    "print(\"对应位置元素相乘的结果:\")\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T03:35:01.785197Z",
     "start_time": "2025-04-10T03:35:01.636868Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最短路径矩阵:\n",
      "[[0. 1. 2. 3.]\n",
      " [1. 0. 1. 2.]\n",
      " [2. 1. 0. 1.]\n",
      " [3. 2. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def floyd_warshall_shortest_path(G, num_nodes):\n",
    "    # 初始化距离矩阵\n",
    "    shortest_path_matrix = np.full((num_nodes, num_nodes), np.inf)\n",
    "    for i in range(num_nodes):\n",
    "        shortest_path_matrix[i, i] = 0\n",
    "    for u, v in G.edges():\n",
    "        shortest_path_matrix[u, v] = 1\n",
    "        shortest_path_matrix[v, u] = 1\n",
    "\n",
    "    # Floyd-Warshall算法核心\n",
    "    for k in range(num_nodes):\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):\n",
    "                shortest_path_matrix[i, j] = min(\n",
    "                    shortest_path_matrix[i, j],\n",
    "                    shortest_path_matrix[i, k] + shortest_path_matrix[k, j]\n",
    "                )\n",
    "\n",
    "    return shortest_path_matrix\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建一个示例图\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from([(0, 1), (1, 2), (2, 3)])\n",
    "    num_nodes = G.number_of_nodes()\n",
    "\n",
    "    # 计算最短路径矩阵\n",
    "    shortest_path_matrix = floyd_warshall_shortest_path(G, num_nodes)\n",
    "    print(\"最短路径矩阵:\")\n",
    "    print(shortest_path_matrix)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-10T14:23:10.030642Z",
     "start_time": "2025-04-10T14:23:09.592922Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
